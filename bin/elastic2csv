#!/usr/bin/env node
/**
 * LambdaCloud copyright 2015.
 *
 */

var program = require('commander');
var _ = require('lodash');
var assert = require('assert');

// Get command line arguments
program.version('0.1.0')
  .option('-H, --host <Elastic Host>', 'Specify Elasticsearch host and port, default: localhost:9200', 'localhost:9200')
  .option('-D, --debug', 'Enable Debugging')
  .option('-i, --indices <Elastic indices>', 'Specify indices')
  .option('-q, --query <Elastic query>', 'Specify query')
  .option('-t, --type <Elastic type>', 'Specify type')
  .option('-c, --columns <columns to export, seprated by commas>', 'Specify the columns of csv, by default all.')
  .option('--api <version>', 'Specify Elasticsearch API version, such as, 1.1, 1.2, 1.3, default: 1.4.', '1.4')
  .parse(process.argv);

// Required options
_.forEach(['indices'], function (opt) {
  assert(program[opt], '--' + opt + ' is missing, exit.');
});

var esLogLevel = 'warning';
if (program.debug) {
  var debug = require('debug');
  debug.enable('elastic-pipe:debug');
  esLogLevel = 'debug';
}

var lambdaUtil = require('../lambda-util');

var elastic = new lambdaUtil.ElasticPipe({
  host: program.host,
  log: esLogLevel,
  keepAlive: false
}, program.indices, program.type, program.query);

var arrayTrans = new lambdaUtil.ArrayTrans();
var stringify = require('csv-stringify');
var elasticDocFlat = new lambdaUtil.ElasticDocFlat();

function init(cb) {
  new lambdaUtil.ElasticMappings().map({
    host: program.host,
    log: esLogLevel,
    keepAlive: false
  }, program.indices, program.type, program.query, cb);
}

var cb = function(mappingKeys) {
  var columns = program.columns ? program.columns.split(',') : mappingKeys;
  var stringifyOption = _.merge({ header: true }, { columns: columns });
  var stringifier = stringify(stringifyOption);

  elastic
    .pipe(arrayTrans)
    .pipe(elasticDocFlat)
    .pipe(stringifier)
    .pipe(process.stdout);
};

init(cb);
